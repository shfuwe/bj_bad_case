{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#按batch_size分\n",
    "from torch.utils.data import DataLoader,TensorDataset,Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义日志（data文件夹下，同级目录新建一个data文件夹）\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "tz = pytz.timezone('Asia/Shanghai')\n",
    "def write_log(w):\n",
    "    file_name = '../data/' + datetime.date.today().strftime('%m%d') + \"_{}.log\".format(\"bert_base4\")\n",
    "    t0 = datetime.datetime.now(tz).strftime('%H:%M:%S')\n",
    "    info = \"{} : {}\".format(t0, w)\n",
    "    print(info)\n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(info + '\\n')\n",
    "# write_log('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# added_token=['##char##']\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\",additional_special_tokens=added_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def text2token(text,tokenizer,max_length=100):\n",
    "    text2id = tokenizer(\n",
    "        text, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids=text2id[\"input_ids\"].tolist()\n",
    "    attention_mask=text2id[\"attention_mask\"].tolist()\n",
    "    return input_ids,attention_mask\n",
    "def data2token(data_,tokenizer):\n",
    "    text=[i for i in data_['title'].values]\n",
    "    input_ids,attention_mask=text2token(text,tokenizer)\n",
    "    data_['input_ids']=input_ids\n",
    "    data_['attention_mask']=attention_mask\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.dataset = df\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.loc[idx, \"title\"]\n",
    "        label = self.dataset.loc[idx, \"label\"]\n",
    "        pre = self.dataset.loc[idx, \"pre\"]\n",
    "        input_ids = self.dataset.loc[idx, \"input_ids\"]\n",
    "        attention_mask = self.dataset.loc[idx, \"attention_mask\"]\n",
    "        sample = {\"text\": text, \"label\": label,\"pre\":pre,\"input_ids\":input_ids,\"attention_mask\":attention_mask}\n",
    "        # print(sample)\n",
    "        return sample\n",
    "    \n",
    "bad_case=pd.read_csv(\"../data/data_test1_bad.csv\")\n",
    "bad_case=data2token(bad_case,tokenizer)\n",
    "bad_loader = DataLoader(\n",
    "    SentimentDataset(bad_case), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.dataset = df\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.loc[idx, \"title\"]\n",
    "        label = self.dataset.loc[idx, \"label\"]\n",
    "        input_ids = self.dataset.loc[idx, \"input_ids\"]\n",
    "        attention_mask = self.dataset.loc[idx, \"attention_mask\"]\n",
    "        sample = {\"text\": text, \"label\": label,\"input_ids\":input_ids,\"attention_mask\":attention_mask}\n",
    "        # print(sample)\n",
    "        return sample\n",
    "\n",
    "\n",
    "data_test1=pd.read_csv(\"../data/data_test1.csv\")\n",
    "data_test1=data2token(data_test1,tokenizer)\n",
    "test1_loader = DataLoader(\n",
    "    SentimentDataset(data_test1), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "data_test2=pd.read_csv(\"../data/data_test2.csv\")\n",
    "data_test2=data2token(data_test2,tokenizer)\n",
    "test2_loader = DataLoader(\n",
    "    SentimentDataset(data_test2), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "data_train=pd.read_csv(\"../data/data_train.csv\")\n",
    "data_train=data2token(data_train,tokenizer)\n",
    "batch_size=16\n",
    "train_loader = DataLoader(\n",
    "    SentimentDataset(data_train), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "data_val=pd.read_csv(\"../data/data_val.csv\")\n",
    "data_val=data2token(data_val,tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    SentimentDataset(data_val), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "def predict_loader(device,test_loader,cls):\n",
    "    with torch.no_grad():\n",
    "        cls.to(device)\n",
    "        cls.eval()\n",
    "        output_all=[]\n",
    "        label_all=[]\n",
    "        for batch_idx,batch in enumerate(test_loader):\n",
    "            print(str(batch_idx)+'/'+str(len(test_loader)),end='\\r')\n",
    "            label=batch['label'].to(device)#batch size * 1\n",
    "            label_all.append(label.view(-1,1))\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device)#batch size * 100\n",
    "            attention_mask=torch.stack(batch['attention_mask']).t().to(device)#batch size * 100\n",
    "            \n",
    "            #计算输出\n",
    "            output = cls(input_ids, attention_mask=attention_mask)#batch size * 1\n",
    "            \n",
    "            #四舍五入\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            output=softmax(output)\n",
    "            output=output.argmax(dim=1)\n",
    "            output_all.append(output)\n",
    "        output_all=torch.cat(output_all,0)\n",
    "        label_all=torch.cat(label_all,0)\n",
    "\n",
    "        output_all=np.array(output_all.cpu())\n",
    "        label_all=np.array(label_all.cpu())\n",
    "        acc_score=metrics.accuracy_score(label_all,output_all)\n",
    "        print(\"准确率:\"+str(acc_score))\n",
    "        print(metrics.classification_report(label_all,output_all))\n",
    "        return label_all,output_all\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class fn_cls(nn.Module):\n",
    "    def __init__(self,device):\n",
    "        super(fn_cls, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model.resize_token_embeddings(len(tokenizer))##############\n",
    "        self.model.to(device)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        self.l1 = nn.Linear(768, 4)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        outputs = self.model(x, attention_mask=attention_mask)\n",
    "#         print(outputs[0])torch.Size([8, 100, 768])\n",
    "#         print(outputs[1])torch.Size([8, 768])\n",
    "#         print(outputs[0][:,0,:])torch.Size([8, 768])\n",
    "        x = outputs[1]\n",
    "#         x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "import torch\n",
    "device0 = torch.device('cuda:7' if torch.cuda.is_available() else \"cpu\")#训练集gpu\n",
    "softmax = nn.Softmax(dim=1)\n",
    "criterion = nn.CrossEntropyLoss()#weight=weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model1对每个badcase预测，然后修正model2\n",
    "def train_one_bad_epoch(device_train,lmd=10):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    cls2.to(device_train)\n",
    "    \n",
    "    epoch_loss=0\n",
    "    total=0\n",
    "    correct=0\n",
    "    output_all=[]\n",
    "    label_all=[]\n",
    "    for batch_idx,batch in enumerate(bad_loader):\n",
    "#         print('___________batch'+str(batch_idx)+'___________')\n",
    "        label=batch['label'].to(device_train)#batch size * 1\n",
    "        pre=batch['pre'].to(device_train)\n",
    "        input_ids=torch.stack(batch['input_ids']).t().to(device_train)#batch size * 100\n",
    "        attention_mask=torch.stack(batch['attention_mask']).t().to(device_train)#batch size * 100\n",
    "                \n",
    "        output2=cls2(input_ids, attention_mask=attention_mask)\n",
    "        output2=softmax(output2)\n",
    "        \n",
    "        loss=0\n",
    "        for i in range(len(output2)):\n",
    "#             print(output[i].tolist(),'\\n',output2[i].tolist(),'\\n','\\n')\n",
    "            loss = loss - torch.log(1-output2[i][pre[i]])\n",
    "            loss=loss/lmd\n",
    "        \n",
    "        optimizer2.zero_grad() # 将所有参数的梯度都置零\n",
    "        loss.backward()    # 误差反向传播计算参数梯度\n",
    "        optimizer2.step()    # 通过梯度做一步参数更新\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total+=len(output2)\n",
    "            epoch_loss+=loss.item()\n",
    "            output2=output2.argmax(dim=1)\n",
    "            add_correct=(output2== pre).sum().item()\n",
    "            correct+=add_correct\n",
    "            acc=correct/total\n",
    "        print(str(batch_idx)+'/'+str(len(bad_loader))+'\\tbatch_loss:'+str(loss.item())+'\\tbad_acc:'+str(acc),end='\\r')\n",
    "        \n",
    "        \n",
    "    return epoch_loss,acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def test(device_test):\n",
    "    cls2.to(device_test)\n",
    "    cls2.eval()\n",
    "\n",
    "    epoch_loss=0\n",
    "    total=0\n",
    "    correct=0\n",
    "    output_all=[]\n",
    "    label_all=[]\n",
    "    for batch_idx,batch in enumerate(test1_loader):\n",
    "        with torch.no_grad():\n",
    "#             print(batch['label'])\n",
    "            label=batch['label'].to(device_test)#batch size * 1\n",
    "            label_all.append(label.view(-1,1))\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device_test)#batch size * 100\n",
    "            attention_mask=torch.stack(batch['attention_mask']).t().to(device_test)#batch size * 100\n",
    "            \n",
    "            #计算输出\n",
    "            output = cls2(input_ids, attention_mask=attention_mask)#batch size * 1\n",
    "            total+=len(output)\n",
    "            \n",
    "            #计算loss\n",
    "            \n",
    "#             print(output,label)\n",
    "            loss = criterion(output, label)\n",
    "            epoch_loss+=loss\n",
    "            ave_loss=epoch_loss/total\n",
    "            \n",
    "            #四舍五入\n",
    "            output=softmax(output)\n",
    "            output=output.argmax(dim=1)\n",
    "            output_all.append(output)\n",
    "            \n",
    "            #计算准确率\n",
    "            add_correct=(output== label).sum().item()\n",
    "            correct+=add_correct\n",
    "            acc=correct/total\n",
    "            \n",
    "            if batch_idx%5==0:\n",
    "                print('[{}/{} ({:.0f}%)]\\t正确分类的样本数：{}，样本总数：{}，准确率：{}，ave_loss：{}'.format(\n",
    "                    batch_idx, len(test1_loader),100.*batch_idx/len(test1_loader), \n",
    "                    correct, total,acc,\n",
    "                    ave_loss\n",
    "                    ),end= \"\\r\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    #结束：\n",
    "    write_log('正确分类的样本数：{}，样本总数：{}，准确率：{}，ave_loss：{}'.format(\n",
    "                    correct, total,acc,\n",
    "                    ave_loss))\n",
    "    \n",
    "#     can't convert cuda:5 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "    output_all=torch.cat(output_all,0)\n",
    "    label_all=torch.cat(label_all,0)\n",
    "    \n",
    "    output_all=np.array(output_all.cpu())\n",
    "    label_all=np.array(label_all.cpu())\n",
    "    acc_score=metrics.accuracy_score(label_all,output_all)\n",
    "    print(metrics.classification_report(label_all,output_all))\n",
    "    write_log(\"准确率:\"+str(acc_score))\n",
    "    \n",
    "    return acc,epoch_loss.item()\n",
    "\n",
    "# test(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(min_test_epoch_loss,device_train,epoch_num,lmd=10):\n",
    "    write_log(\"______________________________________________\")\n",
    "    write_log(\"______________________________________________\")\n",
    "    write_log(\"_______________train epoch\"+str(epoch_num)+\" start_______________\")\n",
    "    write_log(\"______________________________________________\")\n",
    "    write_log(\"______________________________________________\")\n",
    "    cls2.to(device_train)\n",
    "    cls2.train()\n",
    "\n",
    "    epoch_loss=0\n",
    "    total=0\n",
    "    correct=0\n",
    "    acc=0\n",
    "    ave_loss=0\n",
    "    output_all=[]\n",
    "    label_all=[]\n",
    "    for batch_idx,batch in enumerate(train_loader):\n",
    "        if batch_idx%500==0:\n",
    "            write_log('正确分类的样本数：{}，样本总数：{}，准确率：{}，ave_loss：{}'.format(\n",
    "                    correct, total,acc,\n",
    "                    ave_loss))\n",
    "            write_log(\"___train_one_bad_epoch___\")\n",
    "            epoch_loss,acc=train_one_bad_epoch(device0,lmd)\n",
    "            write_log(\"bad_epoch_loss:\"+str(epoch_loss)+\"\\tbad_acc:\"+str(acc))\n",
    "            \n",
    "        label=batch['label'].to(device_train)#batch size * 1\n",
    "        label_all.append(label.view(-1,1))\n",
    "        input_ids=torch.stack(batch['input_ids']).t().to(device_train)#batch size * 100\n",
    "        attention_mask=torch.stack(batch['attention_mask']).t().to(device_train)#batch size * 100\n",
    "\n",
    "        #计算输出\n",
    "        output = cls2(input_ids, attention_mask=attention_mask)#batch size * 1\n",
    "\n",
    "        #计算loss\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #四舍五入\n",
    "            output=softmax(output)\n",
    "            output=output.argmax(dim=1)\n",
    "            output_all.append(output)\n",
    "            total+=len(output)\n",
    "            \n",
    "            #epoch_loss\n",
    "            epoch_loss+=loss\n",
    "            ave_loss=epoch_loss/total\n",
    "            \n",
    "            #计算准确率\n",
    "            add_correct=(output== label).sum().item()\n",
    "            correct+=add_correct\n",
    "            acc=correct/total\n",
    "            \n",
    "            if batch_idx%5==0:\n",
    "                print('[{}/{} ({:.0f}%)]\\t正确分类的样本数：{}，样本总数：{}，准确率：{}，ave_loss：{}'.format(\n",
    "                    batch_idx, len(train_loader),100.*batch_idx/len(train_loader), \n",
    "                    correct, total,acc,\n",
    "                    ave_loss\n",
    "                    ),end= \"\\r\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    #结束：\n",
    "    \n",
    "#     can't convert cuda:5 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "    with torch.no_grad():\n",
    "        output_all=torch.cat(output_all,0)\n",
    "        label_all=torch.cat(label_all,0)\n",
    "\n",
    "        output_all=np.array(output_all.cpu())\n",
    "        label_all=np.array(label_all.cpu())\n",
    "        acc_score=metrics.accuracy_score(label_all,output_all)\n",
    "        \n",
    "#     print(metrics.classification_report(label_all,output_all))\n",
    "    write_log('__________________train end__________________')\n",
    "    write_log('正确分类的样本数：{}，样本总数：{}，准确率：{}，ave_loss：{}'.format(\n",
    "                    correct, total,acc,\n",
    "                    ave_loss))\n",
    "    \n",
    "    write_log(\"准确率:\"+str(acc_score))\n",
    "    \n",
    "    write_log('__________________test start__________________')\n",
    "    test_acc,test_epoch_loss=test(device0)\n",
    "    if min_test_epoch_loss>test_epoch_loss:\n",
    "        min_test_epoch_loss=test_epoch_loss\n",
    "        write_log(\"store model\")\n",
    "        end = time.time()\n",
    "        torch.save(cls2,\"../data/cls_bad_\"+str(epoch_num)+'_'+str(round(test_acc,5))+'_'+str(round(test_epoch_loss,5))+\".model\")\n",
    "    \n",
    "    write_log('__________________test end__________________')\n",
    "    write_log('train_acc:'+str(acc)+'  train_epoch_loss:'+str(epoch_loss.item())+'  test_acc:'+str(test_acc)+'  test_epoch_loss:'+str(test_epoch_loss))\n",
    "    \n",
    "    \n",
    "    train_acc_l.append(acc)\n",
    "    train_epoch_loss_l.append(epoch_loss.item())\n",
    "    test_acc_l.append(test_acc)\n",
    "    test_epoch_loss_l.append(test_epoch_loss)\n",
    "    write_log(\"______________________________________________\")\n",
    "    write_log(\"______________________________________________\")\n",
    "    write_log(\"_______________train epoch \"+str(epoch_num)+\" end_______________\")\n",
    "    write_log(\"______________________________________________\")\n",
    "    write_log(\"______________________________________________\")\n",
    "    return min_test_epoch_loss\n",
    "    \n",
    "\n",
    "    \n",
    "def train(epoch_num):\n",
    "    min_test_epoch_loss=999999\n",
    "    for i in range(epoch_num):\n",
    "        min_test_epoch_loss=train_one_epoch(min_test_epoch_loss,device0,i)\n",
    "\n",
    "    \n",
    "# train_one_epoch(device0,0)\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "cls=torch.load(\"../data/cls_6_0.88785_266.58456.model\",map_location=device0)\n",
    "cls2=torch.load(\"../data/cls_6_0.88785_266.58456.model\",map_location=device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:26:09 : ______________________________________________\n",
      "21:26:09 : ______________________________________________\n",
      "21:26:09 : _______________train epoch0 start_______________\n",
      "21:26:09 : ______________________________________________\n",
      "21:26:09 : ______________________________________________\n",
      "21:26:09 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "21:26:09 : ___train_one_bad_epoch___\n",
      "21:26:31 : bad_epoch_loss:27.687273893505335\tbad_acc:0.7703885194259713\n",
      "21:27:31 : 正确分类的样本数：7300，样本总数：8000，准确率：0.9125，ave_loss：0.02005632035434246.020037708804011345\n",
      "21:27:31 : ___train_one_bad_epoch___\n",
      "21:27:53 : bad_epoch_loss:27.673703121952713\tbad_acc:0.7871893594679734\n",
      "21:28:53 : 正确分类的样本数：14618，样本总数：16000，准确率：0.913625，ave_loss：0.00998687837272882599758291617035875\n",
      "21:28:53 : ___train_one_bad_epoch___\n",
      "21:29:16 : bad_epoch_loss:24.772423620335758\tbad_acc:0.7651382569128456\n",
      "21:30:16 : 正确分类的样本数：21891，样本总数：24000，准确率：0.912125，ave_loss：0.006555906031280756065166424028575425\n",
      "21:30:16 : ___train_one_bad_epoch___\n",
      "21:30:38 : bad_epoch_loss:27.632105093915015\tbad_acc:0.7738886944347217\n",
      "21:31:38 : 正确分类的样本数：29172，样本总数：32000，准确率：0.911625，ave_loss：0.004975248128175735549572563730180265\n",
      "21:31:38 : ___train_one_bad_epoch___\n",
      "21:32:01 : bad_epoch_loss:25.320941555313766\tbad_acc:0.7815890794539727\n",
      "21:33:01 : 正确分类的样本数：36431，样本总数：40000，准确率：0.910775，ave_loss：0.003919291310012340538839124608784914\n",
      "21:33:01 : ___train_one_bad_epoch___\n",
      "21:33:23 : bad_epoch_loss:25.950127562507987\tbad_acc:0.7913895694784739\n",
      "21:34:23 : 正确分类的样本数：43681，样本总数：48000，准确率：0.9100208333333333，ave_loss：0.00341929751448333262875234\n",
      "21:34:23 : ___train_one_bad_epoch___\n",
      "21:34:46 : bad_epoch_loss:23.196309114806354\tbad_acc:0.7647882394119706\n",
      "21:35:45 : 正确分类的样本数：50965，样本总数：56000，准确率：0.9100892857142857，ave_loss：0.00280595105141401328724194\n",
      "21:35:45 : ___train_one_bad_epoch___\n",
      "21:36:08 : bad_epoch_loss:26.081360534764826\tbad_acc:0.7311865593279664\n",
      "21:37:06 : __________________train end__________________58906171601，ave_loss：0.0024509301874786615\n",
      "21:37:06 : 正确分类的样本数：58064，样本总数：63800，准确率：0.9100940438871473，ave_loss：0.0024536675773561\n",
      "21:37:06 : 准确率:0.9100940438871473\n",
      "21:37:06 : __________________test start__________________\n",
      "21:38:10 : 正确分类的样本数：22793，样本总数：25520，准确率：0.8931426332288401，ave_loss：0.01980389468371868969809532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      6380\n",
      "           1       0.91      0.96      0.94      6380\n",
      "           2       0.88      0.84      0.86      6380\n",
      "           3       0.86      0.89      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n",
      "21:38:10 : 准确率:0.8931426332288401\n",
      "21:38:10 : store model\n",
      "21:38:11 : __________________test end__________________\n",
      "21:38:11 : train_acc:0.9100940438871473  train_epoch_loss:156.5439910888672  test_acc:0.8931426332288401  test_epoch_loss:505.3953857421875\n",
      "21:38:11 : ______________________________________________\n",
      "21:38:11 : ______________________________________________\n",
      "21:38:11 : _______________train epoch 0 end_______________\n",
      "21:38:11 : ______________________________________________\n",
      "21:38:11 : ______________________________________________\n",
      "21:38:11 : ______________________________________________\n",
      "21:38:11 : ______________________________________________\n",
      "21:38:11 : _______________train epoch1 start_______________\n",
      "21:38:11 : ______________________________________________\n",
      "21:38:11 : ______________________________________________\n",
      "21:38:11 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "21:38:11 : ___train_one_bad_epoch___\n",
      "21:38:33 : bad_epoch_loss:26.49052538909018\tbad_acc:0.7696884844242212\n",
      "21:39:33 : 正确分类的样本数：7335，样本总数：8000，准确率：0.916875，ave_loss：0.0186061635613441478638009205460556\n",
      "21:39:33 : ___train_one_bad_epoch___\n",
      "21:39:56 : bad_epoch_loss:25.213324853219092\tbad_acc:0.7556877843892195\n",
      "21:40:55 : 正确分类的样本数：14641，样本总数：16000，准确率：0.9150625，ave_loss：0.0095287002623081294842007383704195\n",
      "21:40:55 : ___train_one_bad_epoch___\n",
      "21:41:18 : bad_epoch_loss:25.42880026018247\tbad_acc:0.7504375218760938\n",
      "21:42:17 : 正确分类的样本数：21990，样本总数：24000，准确率：0.91625，ave_loss：0.0061370329931378365061282664537429815\n",
      "21:42:17 : ___train_one_bad_epoch___\n",
      "21:43:40 : 正确分类的样本数：29303，样本总数：32000，准确率：0.91571875，ave_loss：0.0047916993498802185749881632626065\n",
      "21:43:40 : ___train_one_bad_epoch___\n",
      "21:44:02 : bad_epoch_loss:27.234610738232732\tbad_acc:0.760238011900595\n",
      "21:45:02 : 正确分类的样本数：36594，样本总数：40000，准确率：0.91485，ave_loss：0.0039234347641468050039114560931921005\n",
      "21:45:02 : ___train_one_bad_epoch___\n",
      "21:45:24 : bad_epoch_loss:26.136998089030385\tbad_acc:0.728036401820091\n",
      "21:46:24 : 正确分类的样本数：43905，样本总数：48000，准确率：0.9146875，ave_loss：0.00323346047662198542003449741750956\n",
      "21:46:24 : ___train_one_bad_epoch___\n",
      "21:46:46 : bad_epoch_loss:25.03180010803044\tbad_acc:0.7500875043752188\n",
      "21:47:46 : 正确分类的样本数：51254，样本总数：56000，准确率：0.91525，ave_loss：0.0026165277231484650025931554846465588\n",
      "21:47:46 : ___train_one_bad_epoch___\n",
      "21:48:09 : bad_epoch_loss:28.032270507887006\tbad_acc:0.7336366818340917\n",
      "21:49:07 : __________________train end__________________35373808329，ave_loss：0.0024182563647627838\n",
      "21:49:07 : 正确分类的样本数：58341，样本总数：63800，准确率：0.914435736677116，ave_loss：0.0024201730266213417\n",
      "21:49:07 : 准确率:0.914435736677116\n",
      "21:49:07 : __________________test start__________________\n",
      "21:50:11 : 正确分类的样本数：22926，样本总数：25520，准确率：0.8983542319749216，ave_loss：0.0188575182110071183955021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      6380\n",
      "           1       0.92      0.96      0.94      6380\n",
      "           2       0.87      0.86      0.87      6380\n",
      "           3       0.88      0.88      0.88      6380\n",
      "\n",
      "    accuracy                           0.90     25520\n",
      "   macro avg       0.90      0.90      0.90     25520\n",
      "weighted avg       0.90      0.90      0.90     25520\n",
      "\n",
      "21:50:11 : 准确率:0.8983542319749216\n",
      "21:50:11 : store model\n",
      "21:50:11 : __________________test end__________________\n",
      "21:50:11 : train_acc:0.914435736677116  train_epoch_loss:154.40704345703125  test_acc:0.8983542319749216  test_epoch_loss:481.24383544921875\n",
      "21:50:11 : ______________________________________________\n",
      "21:50:11 : ______________________________________________\n",
      "21:50:11 : _______________train epoch 1 end_______________\n",
      "21:50:11 : ______________________________________________\n",
      "21:50:11 : ______________________________________________\n",
      "21:50:11 : ______________________________________________\n",
      "21:50:11 : ______________________________________________\n",
      "21:50:11 : _______________train epoch2 start_______________\n",
      "21:50:11 : ______________________________________________\n",
      "21:50:11 : ______________________________________________\n",
      "21:50:11 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "21:50:11 : ___train_one_bad_epoch___\n",
      "21:50:34 : bad_epoch_loss:25.74619062617421\tbad_acc:0.7339866993349667\n",
      "21:51:34 : 正确分类的样本数：7398，样本总数：8000，准确率：0.92475，ave_loss：0.0174562968313694.017521362751722336\n",
      "21:51:34 : ___train_one_bad_epoch___\n",
      "21:51:56 : bad_epoch_loss:26.273227385245264\tbad_acc:0.7224361218060903\n",
      "21:52:56 : 正确分类的样本数：14777，样本总数：16000，准确率：0.9235625，ave_loss：0.0088719800114631658442470878362665\n",
      "21:52:56 : ___train_one_bad_epoch___\n",
      "21:53:18 : bad_epoch_loss:28.012136332690716\tbad_acc:0.7339866993349667\n",
      "21:54:18 : 正确分类的样本数：22114，样本总数：24000，准确率：0.9214166666666667，ave_loss：0.00620330357924103745094015\n",
      "21:54:18 : ___train_one_bad_epoch___\n",
      "21:54:40 : bad_epoch_loss:23.64251859113574\tbad_acc:0.7311865593279664\n",
      "21:55:40 : 正确分类的样本数：29463，样本总数：32000，准确率：0.92071875，ave_loss：0.0044573890045285225245897233486226\n",
      "21:55:40 : ___train_one_bad_epoch___\n",
      "21:56:03 : bad_epoch_loss:26.486216835211962\tbad_acc:0.6916345817290864\n",
      "21:57:02 : 正确分类的样本数：36850，样本总数：40000，准确率：0.92125，ave_loss：0.0035323442425578833035186971072107553\n",
      "21:57:02 : ___train_one_bad_epoch___\n",
      "21:57:25 : bad_epoch_loss:25.630059105344117\tbad_acc:0.6954847742387119\n",
      "21:58:24 : 正确分类的样本数：44177，样本总数：48000，准确率：0.9203541666666667，ave_loss：0.00306373275816440635831833\n",
      "21:58:24 : ___train_one_bad_epoch___\n",
      "21:58:47 : bad_epoch_loss:24.868706047534943\tbad_acc:0.7049352467623381\n",
      "21:59:46 : 正确分类的样本数：51553，样本总数：56000，准确率：0.9205892857142857，ave_loss：0.00257725501433014872200463\n",
      "21:59:46 : ___train_one_bad_epoch___\n",
      "22:00:09 : bad_epoch_loss:25.264382985420525\tbad_acc:0.7003850192509625\n",
      "22:01:07 : __________________train end__________________07727044657，ave_loss：0.0022862572222948074\n",
      "22:01:07 : 正确分类的样本数：58711，样本总数：63800，准确率：0.9202351097178684，ave_loss：0.002288385294377804\n",
      "22:01:07 : 准确率:0.9202351097178684\n",
      "22:01:07 : __________________test start__________________\n",
      "22:02:10 : 正确分类的样本数：23035，样本总数：25520，准确率：0.9026253918495298，ave_loss：0.01799706369638443847658157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      6380\n",
      "           1       0.93      0.96      0.94      6380\n",
      "           2       0.86      0.88      0.87      6380\n",
      "           3       0.89      0.88      0.88      6380\n",
      "\n",
      "    accuracy                           0.90     25520\n",
      "   macro avg       0.90      0.90      0.90     25520\n",
      "weighted avg       0.90      0.90      0.90     25520\n",
      "\n",
      "22:02:11 : 准确率:0.9026253918495298\n",
      "22:02:11 : store model\n",
      "22:02:11 : __________________test end__________________\n",
      "22:02:11 : train_acc:0.9202351097178684  train_epoch_loss:145.99899291992188  test_acc:0.9026253918495298  test_epoch_loss:459.2850646972656\n",
      "22:02:11 : ______________________________________________\n",
      "22:02:11 : ______________________________________________\n",
      "22:02:11 : _______________train epoch 2 end_______________\n",
      "22:02:11 : ______________________________________________\n",
      "22:02:11 : ______________________________________________\n",
      "22:02:11 : ______________________________________________\n",
      "22:02:11 : ______________________________________________\n",
      "22:02:11 : _______________train epoch3 start_______________\n",
      "22:02:11 : ______________________________________________\n",
      "22:02:11 : ______________________________________________\n",
      "22:02:11 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "22:02:11 : ___train_one_bad_epoch___\n",
      "22:02:33 : bad_epoch_loss:26.302227071952075\tbad_acc:0.687784389219461\n",
      "22:03:33 : 正确分类的样本数：7388，样本总数：8000，准确率：0.9235，ave_loss：0.018018241971731186018031293526291847\n",
      "22:03:33 : ___train_one_bad_epoch___\n",
      "22:03:55 : bad_epoch_loss:24.515236062929034\tbad_acc:0.704235211760588\n",
      "22:04:55 : 正确分类的样本数：14813，样本总数：16000，准确率：0.9258125，ave_loss：0.0084916492924094247120862454176284\n",
      "22:04:55 : ___train_one_bad_epoch___\n",
      "22:05:17 : bad_epoch_loss:23.835705504752696\tbad_acc:0.6975848792439622\n",
      "22:06:16 : 正确分类的样本数：22243，样本总数：24000，准确率：0.9267916666666667，ave_loss：0.00547301722690463101827145\n",
      "22:06:16 : ___train_one_bad_epoch___\n",
      "22:06:39 : bad_epoch_loss:24.520530123263597\tbad_acc:0.6909345467273363\n",
      "22:07:38 : 正确分类的样本数：29643，样本总数：32000，准确率：0.92634375，ave_loss：0.0042332885786890982045442387461664\n",
      "22:07:38 : ___train_one_bad_epoch___\n",
      "22:08:01 : bad_epoch_loss:24.511019214056432\tbad_acc:0.7017850892544627\n",
      "22:09:00 : 正确分类的样本数：37059，样本总数：40000，准确率：0.926475，ave_loss：0.003340787021443248033286316320300102\n",
      "22:09:00 : ___train_one_bad_epoch___\n",
      "22:09:23 : bad_epoch_loss:24.566603188868612\tbad_acc:0.6909345467273363\n",
      "22:10:22 : 正确分类的样本数：44449，样本总数：48000，准确率：0.9260208333333333，ave_loss：0.00275580212473869322387264\n",
      "22:10:22 : ___train_one_bad_epoch___\n",
      "22:10:45 : bad_epoch_loss:27.062311688438058\tbad_acc:0.672033601680084\n",
      "22:11:44 : 正确分类的样本数：51850，样本总数：56000，准确率：0.9258928571428572，ave_loss：0.00246790098026394841806974\n",
      "22:11:44 : ___train_one_bad_epoch___\n",
      "22:12:06 : bad_epoch_loss:25.824047200381756\tbad_acc:0.6678333916695834\n",
      "22:13:04 : __________________train end__________________30506773708，ave_loss：0.0020884876139461994\n",
      "22:13:04 : 正确分类的样本数：59060，样本总数：63800，准确率：0.925705329153605，ave_loss：0.002091443631798029\n",
      "22:13:04 : 准确率:0.925705329153605\n",
      "22:13:04 : __________________test start__________________\n",
      "22:14:08 : 正确分类的样本数：23075，样本总数：25520，准确率：0.904192789968652，ave_loss：0.017527973279356956067276955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      6380\n",
      "           1       0.94      0.95      0.95      6380\n",
      "           2       0.87      0.87      0.87      6380\n",
      "           3       0.87      0.91      0.89      6380\n",
      "\n",
      "    accuracy                           0.90     25520\n",
      "   macro avg       0.90      0.90      0.90     25520\n",
      "weighted avg       0.90      0.90      0.90     25520\n",
      "\n",
      "22:14:08 : 准确率:0.904192789968652\n",
      "22:14:08 : store model\n",
      "22:14:09 : __________________test end__________________\n",
      "22:14:09 : train_acc:0.925705329153605  train_epoch_loss:133.43411254882812  test_acc:0.904192789968652  test_epoch_loss:447.3138732910156\n",
      "22:14:09 : ______________________________________________\n",
      "22:14:09 : ______________________________________________\n",
      "22:14:09 : _______________train epoch 3 end_______________\n",
      "22:14:09 : ______________________________________________\n",
      "22:14:09 : ______________________________________________\n",
      "22:14:09 : ______________________________________________\n",
      "22:14:09 : ______________________________________________\n",
      "22:14:09 : _______________train epoch4 start_______________\n",
      "22:14:09 : ______________________________________________\n",
      "22:14:09 : ______________________________________________\n",
      "22:14:09 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "22:14:09 : ___train_one_bad_epoch___\n",
      "22:14:31 : bad_epoch_loss:23.26661481661722\tbad_acc:0.6503325166258312\n",
      "22:15:30 : 正确分类的样本数：7488，样本总数：8000，准确率：0.936，ave_loss：0.015139168128371239.015085077844560146\n",
      "22:15:30 : ___train_one_bad_epoch___\n",
      "22:15:53 : bad_epoch_loss:26.758557906607166\tbad_acc:0.6709835491774588\n",
      "22:16:52 : 正确分类的样本数：14943，样本总数：16000，准确率：0.9339375，ave_loss：0.0080677764490246770419247969985915\n",
      "22:16:52 : ___train_one_bad_epoch___\n",
      "22:17:15 : bad_epoch_loss:23.2132252859883\tbad_acc:0.6464823241162058\n",
      "22:18:14 : 正确分类的样本数：22448，样本总数：24000，准确率：0.9353333333333333，ave_loss：0.00504107121378183411203485\n",
      "22:18:14 : ___train_one_bad_epoch___\n",
      "22:18:37 : bad_epoch_loss:22.575385014875792\tbad_acc:0.6587329366468323\n",
      "22:19:36 : 正确分类的样本数：29876，样本总数：32000，准确率：0.933625，ave_loss：0.004099600017070770040896749123930937\n",
      "22:19:36 : ___train_one_bad_epoch___\n",
      "22:19:58 : bad_epoch_loss:22.970271442551166\tbad_acc:0.6489324466223311\n",
      "22:20:58 : 正确分类的样本数：37282，样本总数：40000，准确率：0.93205，ave_loss：0.0033006067387759686032936709467321634\n",
      "22:20:58 : ___train_one_bad_epoch___\n",
      "22:21:20 : bad_epoch_loss:22.006925964262336\tbad_acc:0.6573328666433321\n",
      "22:22:20 : 正确分类的样本数：44691，样本总数：48000，准确率：0.9310625，ave_loss：0.00273040030151605627190609835088253\n",
      "22:22:20 : ___train_one_bad_epoch___\n",
      "22:22:43 : bad_epoch_loss:22.170900948811322\tbad_acc:0.6342317115855792\n",
      "22:23:42 : 正确分类的样本数：52097，样本总数：56000，准确率：0.9303035714285715，ave_loss：0.00228996947407722472927687\n",
      "22:23:42 : ___train_one_bad_epoch___\n",
      "22:24:05 : bad_epoch_loss:23.29148212634027\tbad_acc:0.6300315015750787\n",
      "22:25:03 : __________________train end__________________88559959859，ave_loss：0.0019688631873577833\n",
      "22:25:03 : 正确分类的样本数：59349，样本总数：63800，准确率：0.9302351097178684，ave_loss：0.0019699838012456894\n",
      "22:25:03 : 准确率:0.9302351097178684\n",
      "22:25:03 : __________________test start__________________\n",
      "22:26:06 : 正确分类的样本数：23193，样本总数：25520，准确率：0.9088166144200627，ave_loss：0.01674258522689342596096992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92      6380\n",
      "           1       0.95      0.95      0.95      6380\n",
      "           2       0.89      0.86      0.88      6380\n",
      "           3       0.87      0.92      0.89      6380\n",
      "\n",
      "    accuracy                           0.91     25520\n",
      "   macro avg       0.91      0.91      0.91     25520\n",
      "weighted avg       0.91      0.91      0.91     25520\n",
      "\n",
      "22:26:06 : 准确率:0.9088166144200627\n",
      "22:26:06 : store model\n",
      "22:26:07 : __________________test end__________________\n",
      "22:26:07 : train_acc:0.9302351097178684  train_epoch_loss:125.68497467041016  test_acc:0.9088166144200627  test_epoch_loss:427.270751953125\n",
      "22:26:07 : ______________________________________________\n",
      "22:26:07 : ______________________________________________\n",
      "22:26:07 : _______________train epoch 4 end_______________\n",
      "22:26:07 : ______________________________________________\n",
      "22:26:07 : ______________________________________________\n",
      "22:26:07 : ______________________________________________\n",
      "22:26:07 : ______________________________________________\n",
      "22:26:07 : _______________train epoch5 start_______________\n",
      "22:26:07 : ______________________________________________\n",
      "22:26:07 : ______________________________________________\n",
      "22:26:07 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "22:26:07 : ___train_one_bad_epoch___\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:26:29 : bad_epoch_loss:24.00541940657422\tbad_acc:0.6275813790689534\n",
      "22:27:29 : 正确分类的样本数：7474，样本总数：8000，准确率：0.93425，ave_loss：0.01535471342504024515391151420772076\n",
      "22:27:29 : ___train_one_bad_epoch___\n",
      "22:27:51 : bad_epoch_loss:25.32161503471434\tbad_acc:0.6104305215260764\n",
      "22:28:50 : 正确分类的样本数：14966，样本总数：16000，准确率：0.935375，ave_loss：0.00766513869166374276654385775327685\n",
      "22:28:50 : ___train_one_bad_epoch___\n",
      "22:29:13 : bad_epoch_loss:22.944695936283097\tbad_acc:0.6212810640532027\n",
      "22:30:12 : 正确分类的样本数：22403，样本总数：24000，准确率：0.9334583333333333，ave_loss：0.00519762048497796122612765\n",
      "22:30:12 : ___train_one_bad_epoch___\n",
      "22:30:35 : bad_epoch_loss:22.26221126737073\tbad_acc:0.6191809590479525\n",
      "22:31:34 : 正确分类的样本数：29870，样本总数：32000，准确率：0.9334375，ave_loss：0.00373371853493154057086259108036757\n",
      "22:31:34 : ___train_one_bad_epoch___\n",
      "22:31:57 : bad_epoch_loss:24.777453887742013\tbad_acc:0.6065803290164509\n",
      "22:32:56 : 正确分类的样本数：37373，样本总数：40000，准确率：0.934325，ave_loss：0.002943891799077391629332954436540604\n",
      "22:32:56 : ___train_one_bad_epoch___\n",
      "22:33:19 : bad_epoch_loss:22.776826663524844\tbad_acc:0.5894294714735737\n",
      "22:34:18 : 正确分类的样本数：44774，样本总数：48000，准确率：0.9327916666666667，ave_loss：0.00266629154793918130383743\n",
      "22:34:18 : ___train_one_bad_epoch___\n",
      "22:34:41 : bad_epoch_loss:19.93304654280655\tbad_acc:0.5869793489674484\n",
      "22:35:40 : 正确分类的样本数：52247，样本总数：56000，准确率：0.9329821428571429，ave_loss：0.00210777437314391140799194\n",
      "22:35:40 : ___train_one_bad_epoch___\n",
      "22:36:03 : bad_epoch_loss:21.11126167792827\tbad_acc:0.5859292964648233\n",
      "22:37:01 : __________________train end__________________86703462117，ave_loss：0.0017542751738801599\n",
      "22:37:01 : 正确分类的样本数：59562，样本总数：63800，准确率：0.9335736677115988，ave_loss：0.0017563957953825593\n",
      "22:37:01 : 准确率:0.9335736677115988\n",
      "22:37:01 : __________________test start__________________\n",
      "22:38:04 : 正确分类的样本数：23296，样本总数：25520，准确率：0.9128526645768025，ave_loss：0.0161905866116285324503174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      6380\n",
      "           1       0.95      0.95      0.95      6380\n",
      "           2       0.89      0.88      0.88      6380\n",
      "           3       0.88      0.91      0.90      6380\n",
      "\n",
      "    accuracy                           0.91     25520\n",
      "   macro avg       0.91      0.91      0.91     25520\n",
      "weighted avg       0.91      0.91      0.91     25520\n",
      "\n",
      "22:38:04 : 准确率:0.9128526645768025\n",
      "22:38:04 : store model\n",
      "22:38:05 : __________________test end__________________\n",
      "22:38:05 : train_acc:0.9335736677115988  train_epoch_loss:112.05805206298828  test_acc:0.9128526645768025  test_epoch_loss:413.18377685546875\n",
      "22:38:05 : ______________________________________________\n",
      "22:38:05 : ______________________________________________\n",
      "22:38:05 : _______________train epoch 5 end_______________\n",
      "22:38:05 : ______________________________________________\n",
      "22:38:05 : ______________________________________________\n",
      "22:38:05 : ______________________________________________\n",
      "22:38:05 : ______________________________________________\n",
      "22:38:05 : _______________train epoch6 start_______________\n",
      "22:38:05 : ______________________________________________\n",
      "22:38:05 : ______________________________________________\n",
      "22:38:05 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "22:38:05 : ___train_one_bad_epoch___\n",
      "22:38:28 : bad_epoch_loss:23.68120510969311\tbad_acc:0.5729786489324467\n",
      "22:39:27 : 正确分类的样本数：7538，样本总数：8000，准确率：0.94225，ave_loss：0.01387095544487238013952719047665596\n",
      "22:39:27 : ___train_one_bad_epoch___\n",
      "22:39:49 : bad_epoch_loss:21.26315687270835\tbad_acc:0.5848792439621981\n",
      "22:40:49 : 正确分类的样本数：15032，样本总数：16000，准确率：0.9395，ave_loss：0.0069586387835443020069383671507239346\n",
      "22:40:49 : ___train_one_bad_epoch___\n",
      "22:41:11 : bad_epoch_loss:21.675653194542974\tbad_acc:0.5964298214910746\n",
      "22:42:11 : 正确分类的样本数：22515，样本总数：24000，准确率：0.938125，ave_loss：0.004742694087326527047379862517118455\n",
      "22:42:11 : ___train_one_bad_epoch___\n",
      "22:42:33 : bad_epoch_loss:21.270850057248026\tbad_acc:0.5841792089604481\n",
      "22:43:33 : 正确分类的样本数：29993，样本总数：32000，准确率：0.93728125，ave_loss：0.0037500169128179553503216542303567\n",
      "22:43:33 : ___train_one_bad_epoch___\n",
      "22:43:55 : bad_epoch_loss:21.291684937430546\tbad_acc:0.5701785089254463\n",
      "22:44:55 : 正确分类的样本数：37499，样本总数：40000，准确率：0.937475，ave_loss：0.002824339782819152028044132050126794\n",
      "22:44:55 : ___train_one_bad_epoch___\n",
      "22:45:17 : bad_epoch_loss:20.270186497247778\tbad_acc:0.5628281414070704\n",
      "22:46:16 : 正确分类的样本数：45006，样本总数：48000，准确率：0.937625，ave_loss：0.002351103583350777634169606119394307\n",
      "22:46:16 : ___train_one_bad_epoch___\n",
      "22:46:39 : bad_epoch_loss:22.872301667695865\tbad_acc:0.5554777738886945\n",
      "22:47:38 : 正确分类的样本数：52496，样本总数：56000，准确率：0.9374285714285714，ave_loss：0.00206191348843276582570505\n",
      "22:47:38 : ___train_one_bad_epoch___\n",
      "22:48:01 : bad_epoch_loss:22.701833768282086\tbad_acc:0.567728386419321\n",
      "22:48:59 : __________________train end__________________48018063221，ave_loss：0.0017423044191673398\n",
      "22:48:59 : 正确分类的样本数：59799，样本总数：63800，准确率：0.9372884012539185，ave_loss：0.0017432887107133865\n",
      "22:48:59 : 准确率:0.9372884012539185\n",
      "22:48:59 : __________________test start__________________\n",
      "22:50:02 : 正确分类的样本数：23386，样本总数：25520，准确率：0.9163793103448276，ave_loss：0.0157711040228605276582756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92      6380\n",
      "           1       0.94      0.97      0.96      6380\n",
      "           2       0.89      0.89      0.89      6380\n",
      "           3       0.88      0.91      0.90      6380\n",
      "\n",
      "    accuracy                           0.92     25520\n",
      "   macro avg       0.92      0.92      0.92     25520\n",
      "weighted avg       0.92      0.92      0.92     25520\n",
      "\n",
      "22:50:02 : 准确率:0.9163793103448276\n",
      "22:50:02 : store model\n",
      "22:50:03 : __________________test end__________________\n",
      "22:50:03 : train_acc:0.9372884012539185  train_epoch_loss:111.2218246459961  test_acc:0.9163793103448276  test_epoch_loss:402.47857666015625\n",
      "22:50:03 : ______________________________________________\n",
      "22:50:03 : ______________________________________________\n",
      "22:50:03 : _______________train epoch 6 end_______________\n",
      "22:50:03 : ______________________________________________\n",
      "22:50:03 : ______________________________________________\n",
      "22:50:03 : ______________________________________________\n",
      "22:50:03 : ______________________________________________\n",
      "22:50:03 : _______________train epoch7 start_______________\n",
      "22:50:03 : ______________________________________________\n",
      "22:50:03 : ______________________________________________\n",
      "22:50:03 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "22:50:03 : ___train_one_bad_epoch___\n",
      "22:50:25 : bad_epoch_loss:23.243887516204268\tbad_acc:0.5547777388869444\n",
      "22:51:25 : 正确分类的样本数：7548，样本总数：8000，准确率：0.9435，ave_loss：0.013878652825951576013852348551154137\n",
      "22:51:25 : ___train_one_bad_epoch___\n",
      "22:51:47 : bad_epoch_loss:21.4440481394995\tbad_acc:0.5456772838641932\n",
      "22:52:47 : 正确分类的样本数：15093，样本总数：16000，准确率：0.9433125，ave_loss：0.0068738255649805078684811703860765\n",
      "22:52:47 : ___train_one_bad_epoch___\n",
      "22:53:09 : bad_epoch_loss:19.90399821777828\tbad_acc:0.543577178858943\n",
      "22:54:09 : 正确分类的样本数：22658，样本总数：24000，准确率：0.9440833333333334，ave_loss：0.00418639602139592276694585\n",
      "22:54:09 : ___train_one_bad_epoch___\n",
      "22:54:31 : bad_epoch_loss:21.087086199549958\tbad_acc:0.5232761638081904\n",
      "22:55:31 : 正确分类的样本数：30176，样本总数：32000，准确率：0.943，ave_loss：0.0034485456999391317.0034338154364377266\n",
      "22:55:31 : ___train_one_bad_epoch___\n",
      "22:55:53 : bad_epoch_loss:20.870946881419513\tbad_acc:0.5271263563178159\n",
      "22:56:53 : 正确分类的样本数：37708，样本总数：40000，准确率：0.9427，ave_loss：0.002592256758362055.0025883647613227367\n",
      "22:56:53 : ___train_one_bad_epoch___\n",
      "22:57:15 : bad_epoch_loss:19.66738444310613\tbad_acc:0.5239761988099405\n",
      "22:58:15 : 正确分类的样本数：45226，样本总数：48000，准确率：0.9422083333333333，ave_loss：0.00221120123751461583349752\n",
      "22:58:15 : ___train_one_bad_epoch___\n",
      "22:58:37 : bad_epoch_loss:21.102536695660092\tbad_acc:0.5271263563178159\n",
      "22:59:37 : 正确分类的样本数：52772，样本总数：56000，准确率：0.9423571428571429，ave_loss：0.001915354863740503814597955\n",
      "22:59:37 : ___train_one_bad_epoch___\n",
      "22:59:59 : bad_epoch_loss:19.521532734390348\tbad_acc:0.5176758837941897\n",
      "23:00:57 : __________________train end__________________46011038635，ave_loss：0.0016019522445276389\n",
      "23:00:57 : 正确分类的样本数：60136，样本总数：63800，准确率：0.9425705329153605，ave_loss：0.0016066047828644514\n",
      "23:00:57 : 准确率:0.9425705329153605\n",
      "23:00:57 : __________________test start__________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:02:01 : 正确分类的样本数：23419，样本总数：25520，准确率：0.9176724137931035，ave_loss：0.0153605500236153641166115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      6380\n",
      "           1       0.96      0.95      0.96      6380\n",
      "           2       0.89      0.89      0.89      6380\n",
      "           3       0.89      0.91      0.90      6380\n",
      "\n",
      "    accuracy                           0.92     25520\n",
      "   macro avg       0.92      0.92      0.92     25520\n",
      "weighted avg       0.92      0.92      0.92     25520\n",
      "\n",
      "23:02:01 : 准确率:0.9176724137931035\n",
      "23:02:01 : store model\n",
      "23:02:01 : __________________test end__________________\n",
      "23:02:01 : train_acc:0.9425705329153605  train_epoch_loss:102.50138854980469  test_acc:0.9176724137931035  test_epoch_loss:392.001220703125\n",
      "23:02:01 : ______________________________________________\n",
      "23:02:01 : ______________________________________________\n",
      "23:02:01 : _______________train epoch 7 end_______________\n",
      "23:02:01 : ______________________________________________\n",
      "23:02:01 : ______________________________________________\n",
      "23:02:01 : ______________________________________________\n",
      "23:02:01 : ______________________________________________\n",
      "23:02:01 : _______________train epoch8 start_______________\n",
      "23:02:01 : ______________________________________________\n",
      "23:02:01 : ______________________________________________\n",
      "23:02:01 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "23:02:01 : ___train_one_bad_epoch___\n",
      "23:02:24 : bad_epoch_loss:19.09193825814873\tbad_acc:0.5092754637731887\n",
      "23:03:23 : 正确分类的样本数：7533，样本总数：8000，准确率：0.941625，ave_loss：0.0128667317330837253990011298631987\n",
      "23:03:23 : ___train_one_bad_epoch___\n",
      "23:03:46 : bad_epoch_loss:20.89245136361569\tbad_acc:0.5166258312915646\n",
      "23:04:45 : 正确分类的样本数：15082，样本总数：16000，准确率：0.942625，ave_loss：0.00641492893919348763905031420290476\n",
      "23:04:45 : ___train_one_bad_epoch___\n",
      "23:05:08 : bad_epoch_loss:19.0464981039986\tbad_acc:0.5068253412670634\n",
      "23:06:07 : 正确分类的样本数：22658，样本总数：24000，准确率：0.9440833333333334，ave_loss：0.00412025908008217870902165\n",
      "23:06:07 : ___train_one_bad_epoch___\n",
      "23:06:30 : bad_epoch_loss:20.656689966039266\tbad_acc:0.4998249912495625\n",
      "23:07:29 : 正确分类的样本数：30231，样本总数：32000，准确率：0.94471875，ave_loss：0.0031172281596809626061493791639805\n",
      "23:07:29 : ___train_one_bad_epoch___\n",
      "23:07:51 : bad_epoch_loss:19.6618727913592\tbad_acc:0.4966748337416871\n",
      "23:08:51 : 正确分类的样本数：37805，样本总数：40000，准确率：0.945125，ave_loss：0.002530642086640000325129078421741724\n",
      "23:08:51 : ___train_one_bad_epoch___\n",
      "23:09:14 : bad_epoch_loss:21.971804606961086\tbad_acc:0.49632481624081204\n",
      "23:10:13 : 正确分类的样本数：45337，样本总数：48000，准确率：0.9445208333333334，ave_loss：0.00216128095053136356104317\n",
      "23:10:13 : ___train_one_bad_epoch___\n",
      "23:10:35 : bad_epoch_loss:20.51757554966025\tbad_acc:0.49737486874343717\n",
      "23:11:35 : 正确分类的样本数：52904，样本总数：56000，准确率：0.9447142857142857，ave_loss：0.001766986446455121167351254\n",
      "23:11:35 : ___train_one_bad_epoch___\n",
      "23:11:57 : bad_epoch_loss:17.978906374191865\tbad_acc:0.49002450122506125\n",
      "23:12:55 : __________________train end__________________3226292022，ave_loss：0.00155627576168626556\n",
      "23:12:55 : 正确分类的样本数：60259，样本总数：63800，准确率：0.9444984326018809，ave_loss：0.0015575755387544632\n",
      "23:12:55 : 准确率:0.9444984326018809\n",
      "23:12:55 : __________________test start__________________\n",
      "23:13:59 : 正确分类的样本数：23487，样本总数：25520，准确率：0.9203369905956112，ave_loss：0.01495425123721361241608906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      6380\n",
      "           1       0.96      0.96      0.96      6380\n",
      "           2       0.91      0.88      0.89      6380\n",
      "           3       0.88      0.93      0.90      6380\n",
      "\n",
      "    accuracy                           0.92     25520\n",
      "   macro avg       0.92      0.92      0.92     25520\n",
      "weighted avg       0.92      0.92      0.92     25520\n",
      "\n",
      "23:13:59 : 准确率:0.9203369905956112\n",
      "23:13:59 : store model\n",
      "23:14:00 : __________________test end__________________\n",
      "23:14:00 : train_acc:0.9444984326018809  train_epoch_loss:99.37332153320312  test_acc:0.9203369905956112  test_epoch_loss:381.6324768066406\n",
      "23:14:00 : ______________________________________________\n",
      "23:14:00 : ______________________________________________\n",
      "23:14:00 : _______________train epoch 8 end_______________\n",
      "23:14:00 : ______________________________________________\n",
      "23:14:00 : ______________________________________________\n",
      "23:14:00 : ______________________________________________\n",
      "23:14:00 : ______________________________________________\n",
      "23:14:00 : _______________train epoch9 start_______________\n",
      "23:14:00 : ______________________________________________\n",
      "23:14:00 : ______________________________________________\n",
      "23:14:00 : 正确分类的样本数：0，样本总数：0，准确率：0，ave_loss：0\n",
      "23:14:00 : ___train_one_bad_epoch___\n",
      "23:14:22 : bad_epoch_loss:19.63114362861961\tbad_acc:0.47497374868743436\n",
      "23:15:22 : 正确分类的样本数：7578，样本总数：8000，准确率：0.94725，ave_loss：0.01207886915653944012103863991796973\n",
      "23:15:22 : ___train_one_bad_epoch___\n",
      "23:15:44 : bad_epoch_loss:18.201854970655404\tbad_acc:0.4711235561778089\n",
      "23:16:44 : 正确分类的样本数：15182，样本总数：16000，准确率：0.948875，ave_loss：0.00559671455994248455903033353388315\n",
      "23:16:44 : ___train_one_bad_epoch___\n",
      "23:17:06 : bad_epoch_loss:20.780599299585447\tbad_acc:0.4770738536926846\n",
      "23:18:06 : 正确分类的样本数：22769，样本总数：24000，准确率：0.9487083333333334，ave_loss：0.00406833691522479107461265\n",
      "23:18:06 : ___train_one_bad_epoch___\n",
      "23:18:28 : bad_epoch_loss:22.865140159614384\tbad_acc:0.45817290864543225\n",
      "23:19:27 : 正确分类的样本数：30355，样本总数：32000，准确率：0.94859375，ave_loss：0.0031094104051589966881352722644806\n",
      "23:19:27 : ___train_one_bad_epoch___\n",
      "23:19:50 : bad_epoch_loss:17.30960320716258\tbad_acc:0.4609730486524326\n",
      "23:20:50 : 正确分类的样本数：37933，样本总数：40000，准确率：0.948325，ave_loss：0.002377531258389353823757955059409144\n",
      "23:20:50 : ___train_one_bad_epoch___\n",
      "23:21:13 : bad_epoch_loss:19.39312119956594\tbad_acc:0.45012250612530624\n",
      "23:22:12 : 正确分类的样本数：45528，样本总数：48000，准确率：0.9485，ave_loss：0.001959585351869464.0019525554962456226\n",
      "23:22:12 : ___train_one_bad_epoch___\n",
      "23:22:35 : bad_epoch_loss:18.59005741472356\tbad_acc:0.4609730486524326\n",
      "23:23:34 : 正确分类的样本数：53104，样本总数：56000，准确率：0.9482857142857143，ave_loss：0.001733682700432837167294565\n",
      "23:23:34 : ___train_one_bad_epoch___\n",
      "23:23:56 : bad_epoch_loss:16.616413229494356\tbad_acc:0.4679733986699335\n",
      "23:25:15 : __________________train end__________________75163070748，ave_loss：0.0014094207435846329\n",
      "23:25:15 : 正确分类的样本数：60509，样本总数：63800，准确率：0.9484169278996866，ave_loss：0.0014097555540502071\n",
      "23:25:15 : 准确率:0.9484169278996866\n",
      "23:25:15 : __________________test start__________________\n",
      "23:27:24 : 正确分类的样本数：23555，样本总数：25520，准确率：0.9230015673981191，ave_loss：0.01460660528391599781915379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      6380\n",
      "           1       0.96      0.96      0.96      6380\n",
      "           2       0.90      0.89      0.90      6380\n",
      "           3       0.90      0.92      0.91      6380\n",
      "\n",
      "    accuracy                           0.92     25520\n",
      "   macro avg       0.92      0.92      0.92     25520\n",
      "weighted avg       0.92      0.92      0.92     25520\n",
      "\n",
      "23:27:24 : 准确率:0.9230015673981191\n",
      "23:27:24 : store model\n",
      "23:27:25 : __________________test end__________________\n",
      "23:27:25 : train_acc:0.9484169278996866  train_epoch_loss:89.9424057006836  test_acc:0.9230015673981191  test_epoch_loss:372.76055908203125\n",
      "23:27:25 : ______________________________________________\n",
      "23:27:25 : ______________________________________________\n",
      "23:27:25 : _______________train epoch 9 end_______________\n",
      "23:27:25 : ______________________________________________\n",
      "23:27:25 : ______________________________________________\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "# cls2.load_state_dict(cls.state_dict())\n",
    "optimizer2 = optim.Adam(cls2.parameters(), lr=1e-6)\n",
    "\n",
    "train_acc_l=[]\n",
    "train_epoch_loss_l=[]\n",
    "test_acc_l=[]\n",
    "test_epoch_loss_l=[]\n",
    "train(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "cls2=fn_cls(device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_from0(epoch_num):\n",
    "    min_test_epoch_loss=999999\n",
    "    for i in range(epoch_num):\n",
    "        min_test_epoch_loss=train_one_epoch_from0(min_test_epoch_loss,device0,i,lmd=1)\n",
    "\n",
    "    \n",
    "# train_one_epoch(device0,0)\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer2 = optim.Adam(cls2.parameters(), lr=1e-6)\n",
    "\n",
    "train_acc_l=[]\n",
    "train_epoch_loss_l=[]\n",
    "test_acc_l=[]\n",
    "test_epoch_loss_l=[]\n",
    "train_from0(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8880485893416928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90      6380\n",
      "           1       0.92      0.95      0.93      6380\n",
      "           2       0.85      0.85      0.85      6380\n",
      "           3       0.87      0.87      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all,output_all=predict_loader(device0,test1_loader,cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.9185736677115988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      6380\n",
      "           1       0.95      0.97      0.96      6380\n",
      "           2       0.89      0.88      0.89      6380\n",
      "           3       0.89      0.92      0.90      6380\n",
      "\n",
      "    accuracy                           0.92     25520\n",
      "   macro avg       0.92      0.92      0.92     25520\n",
      "weighted avg       0.92      0.92      0.92     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls3=torch.load(\"../data/cls2_8_0.86577_317.2764.model\",map_location=device0)\n",
    "label_all,output_all=predict_loader(device0,test1_loader,cls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_all,output_all=predict_loader(device0,test1_loader,cls2)\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.93      0.93      0.93      6380\n",
    "#            1       0.96      0.96      0.96      6380\n",
    "#            2       0.90      0.89      0.90      6380\n",
    "#            3       0.90      0.92      0.91      6380\n",
    "\n",
    "#     accuracy                           0.92     25520\n",
    "#    macro avg       0.92      0.92      0.92     25520\n",
    "# weighted avg       0.92      0.92      0.92     25520\n",
    "\n",
    "# 23:27:24 : 准确率:0.9230015673981191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.9170846394984326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      6380\n",
      "           1       0.94      0.97      0.95      6380\n",
      "           2       0.90      0.88      0.89      6380\n",
      "           3       0.90      0.91      0.90      6380\n",
      "\n",
      "    accuracy                           0.92     25520\n",
      "   macro avg       0.92      0.92      0.92     25520\n",
      "weighted avg       0.92      0.92      0.92     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls3=torch.load(\"../data/cls_bad_9_0.91708_396.36725.model\",map_location=device0)\n",
    "label_all,output_all=predict_loader(device0,test1_loader,cls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8887931034482759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      6380\n",
      "           1       0.92      0.95      0.93      6380\n",
      "           2       0.86      0.84      0.85      6380\n",
      "           3       0.86      0.88      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all,output_all=predict_loader(device0,test2_loader,cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8913009404388714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      6380\n",
      "           1       0.92      0.95      0.94      6380\n",
      "           2       0.86      0.84      0.85      6380\n",
      "           3       0.85      0.88      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls3=torch.load(\"../data/cls2_8_0.86577_317.2764.model\",map_location=device0)\n",
    "label_all,output_all=predict_loader(device0,test2_loader,cls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8918495297805643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      6380\n",
      "           1       0.93      0.94      0.94      6380\n",
      "           2       0.87      0.85      0.86      6380\n",
      "           3       0.86      0.89      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all,output_all=predict_loader(device0,test2_loader,cls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8906347962382445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      6380\n",
      "           1       0.92      0.95      0.94      6380\n",
      "           2       0.87      0.84      0.85      6380\n",
      "           3       0.86      0.88      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all,output_all=predict_loader(device0,test2_loader,cls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "cls2=torch.load(\"../data/cls_6_0.88785_266.58456.model\",map_location=device0)\n",
    "optimizer2 = optim.Adam(cls2.parameters(), lr=1e-4)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"____________________epoch:\"+str(i)+\"____________________\")\n",
    "    epoch_loss=train_one_epoch(device0,0)\n",
    "    print(epoch_loss)\n",
    "    label_all,output_all=predict_loader(device0,test1_loader,cls2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(device,s_l,cls):\n",
    "    with torch.no_grad():\n",
    "        cls.to(device)\n",
    "        cls.eval()\n",
    "        text2id = tokenizer(\n",
    "            s_l, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids=text2id[\"input_ids\"].to(device)\n",
    "        mask=text2id[\"attention_mask\"].to(device)\n",
    "        output = cls(input_ids, attention_mask=mask)\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        output1=softmax(output)\n",
    "        output2=output.argmax(dim=1)\n",
    "        return output1,output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.6244e-02, 9.7378e-01, 5.3007e-03, 4.6791e-03],\n",
      "        [6.1406e-02, 1.4047e-03, 9.3121e-01, 5.9830e-03],\n",
      "        [7.6313e-03, 9.8954e-01, 2.2822e-03, 5.4985e-04],\n",
      "        [9.9728e-01, 8.1377e-04, 1.0767e-03, 8.2985e-04]], device='cuda:6'), tensor([1, 2, 1, 0], device='cuda:6'))\n",
      "(tensor([[1.6244e-02, 9.7378e-01, 5.3007e-03, 4.6791e-03],\n",
      "        [6.1406e-02, 1.4047e-03, 9.3121e-01, 5.9830e-03],\n",
      "        [7.6313e-03, 9.8954e-01, 2.2822e-03, 5.4985e-04],\n",
      "        [9.9728e-01, 8.1377e-04, 1.0767e-03, 8.2985e-04]], device='cuda:6'), tensor([1, 2, 1, 0], device='cuda:6'))\n"
     ]
    }
   ],
   "source": [
    "s=['Echoes Repeats Success','\"Stocks Finish Lower, Retail Sector Weighs\"','Report indicates Wannstedt out','Conference Members Back Iraqi Efforts']\n",
    "print(predict(device0,s,cls))\n",
    "print(predict(device0,s,cls2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "end=time.time()\n",
    "torch.save(cls2,\"../data/cls2_bad_\"+str(end)+\".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0.02694982503663435\n",
    "# 0.20794415416798367\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs0",
   "language": "python",
   "name": "bs0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
