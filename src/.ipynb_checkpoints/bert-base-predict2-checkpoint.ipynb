{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class fn_cls(nn.Module):\n",
    "    def __init__(self,device):\n",
    "        super(fn_cls, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model.resize_token_embeddings(len(tokenizer))##############\n",
    "        self.model.to(device)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        self.l1 = nn.Linear(768, leishu)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        outputs = self.model(x, attention_mask=attention_mask)\n",
    "#         print(outputs[0])torch.Size([8, 100, 768])\n",
    "#         print(outputs[1])torch.Size([8, 768])\n",
    "#         print(outputs[0][:,0,:])torch.Size([8, 768])\n",
    "        x = outputs[1]\n",
    "#         x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device0 = torch.device('cuda:4' if torch.cuda.is_available() else \"cpu\")#训练集gpu\n",
    "cls2=torch.load(\"../data/cls2_8_0.86577_317.2764.model\",map_location=device0)\n",
    "cls2_bad=torch.load(\"../data/cls2_bad_1639738844.6008477.model\",map_location=device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "softmax = nn.Softmax(dim=1)\n",
    "def predict(device,s_l,cls):\n",
    "    with torch.no_grad():\n",
    "        cls.to(device)\n",
    "        cls.eval()\n",
    "        text2id = tokenizer(\n",
    "            s_l, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids=text2id[\"input_ids\"].to(device)\n",
    "        mask=text2id[\"attention_mask\"].to(device)\n",
    "        output = cls(input_ids, attention_mask=mask)\n",
    "\n",
    "        output1=softmax(output)\n",
    "        output2=output.argmax(dim=1)\n",
    "        return output1,output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[6.3786e-02, 5.7162e-01, 5.8857e-02, 3.0574e-01],\n",
      "        [9.1464e-02, 1.3244e-03, 9.0111e-01, 6.0977e-03],\n",
      "        [3.7518e-03, 9.9471e-01, 9.5049e-04, 5.9205e-04],\n",
      "        [9.9791e-01, 5.1385e-04, 9.2788e-04, 6.4574e-04]], device='cuda:4'), tensor([1, 2, 1, 0], device='cuda:4'))\n",
      "(tensor([[0.0724, 0.6693, 0.1078, 0.1505],\n",
      "        [0.0473, 0.0029, 0.9362, 0.0136],\n",
      "        [0.0618, 0.7723, 0.1359, 0.0299],\n",
      "        [0.9034, 0.0522, 0.0215, 0.0229]], device='cuda:4'), tensor([1, 2, 1, 0], device='cuda:4'))\n"
     ]
    }
   ],
   "source": [
    "s=['Echoes Repeats Success','\"Stocks Finish Lower, Retail Sector Weighs\"','Report indicates Wannstedt out','Conference Members Back Iraqi Efforts']\n",
    "print(predict(device0,s,cls2))\n",
    "print(predict(device0,s,cls2_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def text2token(text,tokenizer,max_length=100):\n",
    "    text2id = tokenizer(\n",
    "        text, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids=text2id[\"input_ids\"].tolist()\n",
    "    attention_mask=text2id[\"attention_mask\"].tolist()\n",
    "    return input_ids,attention_mask\n",
    "def data2token(data_,tokenizer):\n",
    "    text=[i for i in data_['title'].values]\n",
    "    input_ids,attention_mask=text2token(text,tokenizer)\n",
    "    data_['input_ids']=input_ids\n",
    "    data_['attention_mask']=attention_mask\n",
    "    return data_\n",
    "data_test2=pd.read_csv(\"../data/data_test2.csv\")\n",
    "data_test2=data2token(data_test2,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.dataset = df\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.loc[idx, \"title\"]\n",
    "        label = self.dataset.loc[idx, \"label\"]\n",
    "        input_ids = self.dataset.loc[idx, \"input_ids\"]\n",
    "        attention_mask = self.dataset.loc[idx, \"attention_mask\"]\n",
    "        sample = {\"text\": text, \"label\": label,\"input_ids\":input_ids,\"attention_mask\":attention_mask}\n",
    "        # print(sample)\n",
    "        return sample\n",
    "    \n",
    "#按batch_size分\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "batch_size=16\n",
    "test2_loader = DataLoader(\n",
    "    SentimentDataset(data_test2), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "def predict_loader(device,test_loader,cls):\n",
    "    with torch.no_grad():\n",
    "        cls.to(device)\n",
    "        cls.eval()\n",
    "        output_all=[]\n",
    "        label_all=[]\n",
    "        for batch_idx,batch in enumerate(test_loader):\n",
    "            print(str(batch_idx)+'/'+str(len(test_loader)),end='\\r')\n",
    "            label=batch['label'].to(device)#batch size * 1\n",
    "            label_all.append(label.view(-1,1))\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device)#batch size * 100\n",
    "            attention_mask=torch.stack(batch['attention_mask']).t().to(device)#batch size * 100\n",
    "            \n",
    "            #计算输出\n",
    "            output = cls(input_ids, attention_mask=attention_mask)#batch size * 1\n",
    "            \n",
    "            #四舍五入\n",
    "            output=softmax(output)\n",
    "            output=output.argmax(dim=1)\n",
    "            output_all.append(output)\n",
    "        output_all=torch.cat(output_all,0)\n",
    "        label_all=torch.cat(label_all,0)\n",
    "\n",
    "        output_all=np.array(output_all.cpu())\n",
    "        label_all=np.array(label_all.cpu())\n",
    "        acc_score=metrics.accuracy_score(label_all,output_all)\n",
    "        print(\"准确率:\"+str(acc_score))\n",
    "        print(metrics.classification_report(label_all,output_all))\n",
    "        return label_all,output_all\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8913009404388714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90      6380\n",
      "           1       0.92      0.95      0.94      6380\n",
      "           2       0.86      0.84      0.85      6380\n",
      "           3       0.85      0.88      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all2,output_all2=predict_loader(device0,test2_loader,cls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8400862068965518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      6380\n",
      "           1       0.91      0.85      0.88      6380\n",
      "           2       0.82      0.80      0.81      6380\n",
      "           3       0.83      0.82      0.82      6380\n",
      "\n",
      "    accuracy                           0.84     25520\n",
      "   macro avg       0.84      0.84      0.84     25520\n",
      "weighted avg       0.84      0.84      0.84     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all2_bad,output_all2_bad=predict_loader(device0,test2_loader,cls2_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8887931034482759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      6380\n",
      "           1       0.92      0.95      0.93      6380\n",
      "           2       0.86      0.84      0.85      6380\n",
      "           3       0.86      0.88      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls=torch.load(\"../data/cls_6_0.88785_266.58456.model\",map_location=device0)\n",
    "label_all,output_all=predict_loader(device0,test2_loader,cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_end():\n",
    "    for i in ['input_ids','attention_mask','pre']:\n",
    "        if i in data_test2.\n",
    "\n",
    "    data_test2['pre']=output_all2\n",
    "    data_test2.to_csv(\"../data/data_test2_out.csv\",index=0)\n",
    "    data_test2_bad=data_test2.loc[data_test2['label']!=data_test2['pre']]\n",
    "    \n",
    "    data_test2_bad.to_csv(\"../data/data_test1_bad.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs0",
   "language": "python",
   "name": "bs0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
