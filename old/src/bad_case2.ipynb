{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bad_case=pd.read_csv(\"../data/data_test1_bad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "# added_token=['##char##']\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\",additional_special_tokens=added_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def text2token(text,tokenizer,max_length=100):\n",
    "    text2id = tokenizer(\n",
    "        text, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids=text2id[\"input_ids\"].tolist()\n",
    "    attention_mask=text2id[\"attention_mask\"].tolist()\n",
    "    return input_ids,attention_mask\n",
    "def data2token(data_,tokenizer):\n",
    "    text=[i for i in data_['title'].values]\n",
    "    input_ids,attention_mask=text2token(text,tokenizer)\n",
    "    data_['input_ids']=input_ids\n",
    "    data_['attention_mask']=attention_mask\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.dataset = df\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.loc[idx, \"title\"]\n",
    "        label = self.dataset.loc[idx, \"label\"]\n",
    "        input_ids = self.dataset.loc[idx, \"input_ids\"]\n",
    "        attention_mask = self.dataset.loc[idx, \"attention_mask\"]\n",
    "        sample = {\"text\": text, \"label\": label,\"input_ids\":input_ids,\"attention_mask\":attention_mask}\n",
    "        # print(sample)\n",
    "        return sample\n",
    "    \n",
    "#按batch_size分\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_case=data2token(bad_case,tokenizer)\n",
    "bad_loader = DataLoader(\n",
    "    SentimentDataset(bad_case), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_test1=pd.read_csv(\"../data/data_test1.csv\")\n",
    "data_test1=data2token(data_test1,tokenizer)\n",
    "test1_loader = DataLoader(\n",
    "    SentimentDataset(data_test1), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "data_test2=pd.read_csv(\"../data/data_test2.csv\")\n",
    "data_test2=data2token(data_test2,tokenizer)\n",
    "test2_loader = DataLoader(\n",
    "    SentimentDataset(data_test2), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "def predict_loader(device,test_loader,cls):\n",
    "    with torch.no_grad():\n",
    "        cls.to(device)\n",
    "        cls.eval()\n",
    "        output_all=[]\n",
    "        label_all=[]\n",
    "        for batch_idx,batch in enumerate(test_loader):\n",
    "            print(str(batch_idx)+'/'+str(len(test_loader)),end='\\r')\n",
    "            label=batch['label'].to(device)#batch size * 1\n",
    "            label_all.append(label.view(-1,1))\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device)#batch size * 100\n",
    "            attention_mask=torch.stack(batch['attention_mask']).t().to(device)#batch size * 100\n",
    "            \n",
    "            #计算输出\n",
    "            output = cls(input_ids, attention_mask=attention_mask)#batch size * 1\n",
    "            \n",
    "            #四舍五入\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            output=softmax(output)\n",
    "            output=output.argmax(dim=1)\n",
    "            output_all.append(output)\n",
    "        output_all=torch.cat(output_all,0)\n",
    "        label_all=torch.cat(label_all,0)\n",
    "\n",
    "        output_all=np.array(output_all.cpu())\n",
    "        label_all=np.array(label_all.cpu())\n",
    "        acc_score=metrics.accuracy_score(label_all,output_all)\n",
    "        print(\"准确率:\"+str(acc_score))\n",
    "        print(metrics.classification_report(label_all,output_all))\n",
    "        return label_all,output_all\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class fn_cls(nn.Module):\n",
    "    def __init__(self,device):\n",
    "        super(fn_cls, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model.resize_token_embeddings(len(tokenizer))##############\n",
    "        self.model.to(device)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        self.l1 = nn.Linear(768, leishu)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        outputs = self.model(x, attention_mask=attention_mask)\n",
    "#         print(outputs[0])torch.Size([8, 100, 768])\n",
    "#         print(outputs[1])torch.Size([8, 768])\n",
    "#         print(outputs[0][:,0,:])torch.Size([8, 768])\n",
    "        x = outputs[1]\n",
    "#         x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "import torch\n",
    "device0 = torch.device('cuda:6' if torch.cuda.is_available() else \"cpu\")#训练集gpu\n",
    "cls=torch.load(\"../data/cls_6_0.88785_266.58456.model\",map_location=device0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2=torch.load(\"../data/cls_6_0.88785_266.58456.model\",map_location=device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.0269)\n",
      "tensor(0.2079)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def asymmetricKL(P,Q):\n",
    "#     print(P,Q)\n",
    "    return sum(P * torch.log(P / Q)) #calculate the kl divergence between P and Q\n",
    " \n",
    "def symmetricalKL(P,Q):\n",
    "    return (asymmetricKL(P,Q)+asymmetricKL(Q,P))/2.00\n",
    "\n",
    "print(symmetricalKL(torch.tensor([0.8,0.1,0.1]),torch.tensor([0.8,0.1,0.1])))\n",
    "print(symmetricalKL(torch.tensor([0.8,0.1,0.1]),torch.tensor([0.7,0.15,0.15])))\n",
    "print(symmetricalKL(torch.tensor([0.8,0.1,0.1]),torch.tensor([0.5,0.25,0.25])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model1对每个badcase预测，然后修正model2\n",
    "def train_one_epoch(device_train,epoch_num):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    cls.to(device_train)\n",
    "    cls2.to(device_train)\n",
    "    \n",
    "    epoch_loss=0\n",
    "    total=0\n",
    "    correct=0\n",
    "    output_all=[]\n",
    "    label_all=[]\n",
    "    for batch_idx,batch in enumerate(bad_loader):\n",
    "#         print('___________batch'+str(batch_idx)+'___________')\n",
    "        with torch.no_grad():\n",
    "            label=batch['label'].to(device_train)#batch size * 1\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device_train)#batch size * 100\n",
    "            attention_mask=torch.stack(batch['attention_mask']).t().to(device_train)#batch size * 100\n",
    "            output = cls(input_ids, attention_mask=attention_mask)#batch size * 1\n",
    "            output=softmax(output)\n",
    "            for i in range(len(output)):\n",
    "                pre_=output[i].argmax(dim=0)\n",
    "                output[i][pre_]=output[i][pre_]*0.3\n",
    "            output=softmax(output)\n",
    "                \n",
    "                \n",
    "        output2=cls2(input_ids, attention_mask=attention_mask)\n",
    "        output2=softmax(output2)\n",
    "\n",
    "        \n",
    "        loss=0\n",
    "        for i in range(len(output2)):\n",
    "#             print(output[i].tolist(),'\\n',output2[i].tolist(),'\\n','\\n')\n",
    "            loss = loss + symmetricalKL(output2[i],output[i])\n",
    "            \n",
    "        print(str(batch_idx)+'/'+str(len(bad_loader))+' batch_loss:'+str(loss.item()),end='\\r')\n",
    "        with torch.no_grad():\n",
    "            epoch_loss+=loss.item()\n",
    "\n",
    "        optimizer2.zero_grad() # 将所有参数的梯度都置零\n",
    "        loss.backward()    # 误差反向传播计算参数梯度\n",
    "        optimizer2.step()    # 通过梯度做一步参数更新\n",
    "    return epoch_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/179 batch_loss:0.11105266213417053\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.44869008660316"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch import optim\n",
    "# cls2.load_state_dict(cls.state_dict())\n",
    "# optimizer2 = optim.Adam(cls2.parameters(), lr=1e-6)\n",
    "\n",
    "epoch_loss=train_one_epoch(device0,0)\n",
    "epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.871512539184953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      6380\n",
      "           1       0.88      0.95      0.92      6380\n",
      "           2       0.83      0.83      0.83      6380\n",
      "           3       0.87      0.82      0.85      6380\n",
      "\n",
      "    accuracy                           0.87     25520\n",
      "   macro avg       0.87      0.87      0.87     25520\n",
      "weighted avg       0.87      0.87      0.87     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all,output_all=predict_loader(device0,test1_loader,cls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8690047021943573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      6380\n",
      "           1       0.88      0.95      0.91      6380\n",
      "           2       0.84      0.82      0.83      6380\n",
      "           3       0.86      0.83      0.85      6380\n",
      "\n",
      "    accuracy                           0.87     25520\n",
      "   macro avg       0.87      0.87      0.87     25520\n",
      "weighted avg       0.87      0.87      0.87     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all,output_all=predict_loader(device0,test2_loader,cls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8880485893416928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90      6380\n",
      "           1       0.92      0.95      0.93      6380\n",
      "           2       0.85      0.85      0.85      6380\n",
      "           3       0.87      0.87      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all,output_all=predict_loader(device0,test1_loader,cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:0.8887931034482759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      6380\n",
      "           1       0.92      0.95      0.93      6380\n",
      "           2       0.86      0.84      0.85      6380\n",
      "           3       0.86      0.88      0.87      6380\n",
      "\n",
      "    accuracy                           0.89     25520\n",
      "   macro avg       0.89      0.89      0.89     25520\n",
      "weighted avg       0.89      0.89      0.89     25520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_all,output_all=predict_loader(device0,test2_loader,cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________epoch:0____________________\n",
      "nan/179 batch_loss:nan\n",
      "准确率:0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40      6380\n",
      "           1       0.00      0.00      0.00      6380\n",
      "           2       0.00      0.00      0.00      6380\n",
      "           3       0.00      0.00      0.00      6380\n",
      "\n",
      "    accuracy                           0.25     25520\n",
      "   macro avg       0.06      0.25      0.10     25520\n",
      "weighted avg       0.06      0.25      0.10     25520\n",
      "\n",
      "____________________epoch:1____________________\n",
      "37/179 batch_loss:nan\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39879/2087084245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"____________________epoch:\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"____________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabel_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest1_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39879/2303083668.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(device_train, epoch_num)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 将所有参数的梯度都置零\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 误差反向传播计算参数梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moptimizer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 通过梯度做一步参数更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "cls2=torch.load(\"../data/cls_6_0.88785_266.58456.model\",map_location=device0)\n",
    "optimizer2 = optim.Adam(cls2.parameters(), lr=1e-4)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"____________________epoch:\"+str(i)+\"____________________\")\n",
    "    epoch_loss=train_one_epoch(device0,0)\n",
    "    print(epoch_loss)\n",
    "    label_all,output_all=predict_loader(device0,test1_loader,cls2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(device,s_l,cls):\n",
    "    with torch.no_grad():\n",
    "        cls.to(device)\n",
    "        cls.eval()\n",
    "        text2id = tokenizer(\n",
    "            s_l, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids=text2id[\"input_ids\"].to(device)\n",
    "        mask=text2id[\"attention_mask\"].to(device)\n",
    "        output = cls(input_ids, attention_mask=mask)\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        output1=softmax(output)\n",
    "        output2=output.argmax(dim=1)\n",
    "        return output1,output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.6244e-02, 9.7378e-01, 5.3007e-03, 4.6791e-03],\n",
      "        [6.1406e-02, 1.4047e-03, 9.3121e-01, 5.9830e-03],\n",
      "        [7.6313e-03, 9.8954e-01, 2.2822e-03, 5.4985e-04],\n",
      "        [9.9728e-01, 8.1377e-04, 1.0767e-03, 8.2985e-04]], device='cuda:6'), tensor([1, 2, 1, 0], device='cuda:6'))\n",
      "(tensor([[1.6244e-02, 9.7378e-01, 5.3007e-03, 4.6791e-03],\n",
      "        [6.1406e-02, 1.4047e-03, 9.3121e-01, 5.9830e-03],\n",
      "        [7.6313e-03, 9.8954e-01, 2.2822e-03, 5.4985e-04],\n",
      "        [9.9728e-01, 8.1377e-04, 1.0767e-03, 8.2985e-04]], device='cuda:6'), tensor([1, 2, 1, 0], device='cuda:6'))\n"
     ]
    }
   ],
   "source": [
    "s=['Echoes Repeats Success','\"Stocks Finish Lower, Retail Sector Weighs\"','Report indicates Wannstedt out','Conference Members Back Iraqi Efforts']\n",
    "print(predict(device0,s,cls))\n",
    "print(predict(device0,s,cls2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "end=time.time()\n",
    "torch.save(cls2,\"../data/cls2_bad_\"+str(end)+\".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0.02694982503663435\n",
    "# 0.20794415416798367\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs0",
   "language": "python",
   "name": "bs0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
